# -*- coding: utf-8 -*-
"""
===============================================================================
PLEASE, READ CAREFULLY!!!!!!!! ================================================
===============================================================================
Include the standard dilution series for your curve in PCR_1 of a batch. On the
CFX manager write them down as 10^0, 10^1, etc. NEVER use 10^ in a sample, this
will screw up this python script.

On each PCR, include a sample mix. This is a random mix of some samples. This 
sample mix is amplified 6 times for each PCR. These samples are used for
normalization within the plates. On the CFX manager, write these samples down 
as 'STD'. Do NOT write anything else or behind it, this will screw up this
python script.

Make sure for follow-up PCRs the threshold is set to the same value as the PCR 
including standard dilution series. Otherwhise, the data is not comparable!

For the export, click in CFX manager on [Export], [Custom Export]. At the top,
select export format as .CSV. Uncheck the box below it named 'Include run 
information header'. For this script you need the Sample Name and Cq, but all
other boxes could be checked if this is desired. Click [Export]. Do this for
all your PCRs. After the analytical run code, make sure there is PCR_#. For all
PCRs the number does not matter, only for the one with the dilution serie, name
this file PCR_1. Save all your .CSVs in one folder. Link to this folder at 
'folder_path'.

In the folder with your .CSVs, also save a .CSV with all your sample names and 
the dilution factor. Name the headers of these columns "Sample" and 'Dilution',
otherwise, this will screw up this python script. Name this file the following:
'analytical_run_code'_dilution_rates.csv. 
===============================================================================
@author: rdebeer
"""
# !!!Variables to set==========================================================
# =============================================================================
folder_path = '//zeus.nioz.nl/mmb/molecular_ecology/mollab_team/Projects/2024/MMB/Nicole/Quantification/Results/exported_data' # Directory where the CSV files are located
std_curve_copies = 4.06 # What is the copies/µL of the standard *10^x
analytical_run_code = 'NIOZ385&NIOZ386' # Analytical run code generated by DAS
# =============================================================================
# Import statements ===========================================================
# =============================================================================
import pandas as pd, numpy as np
import glob
import os
import statistics
import math
from scipy import stats
from matplotlib import pyplot as plt
from openpyxl import load_workbook
from openpyxl.formatting.rule import ColorScaleRule
from openpyxl.utils import get_column_letter
# =============================================================================
# =============================================================================
# Loading in the raw data =====================================================
# =============================================================================
# List of file names
# Only keeps the file names if the name contains 'PCR_'
file_names = glob.glob(os.path.join(folder_path, analytical_run_code + '_*.csv'))
file_names = [file for file in file_names if 'PCR_' in os.path.basename(file)]

# Empty dictionary for the DataFrames
PCRs = {}

# Load DataFrames and save them with the name 'PCR' followed by the number from the file name
for file in file_names:
    # Extract the number from the file name
    df_name = os.path.basename(file).split('_')[-1].split('.')[0]
    # Read the CSV file and select only 'Sample' and 'Cq' columns
    PCR = pd.read_csv(file, usecols=['Sample', 'Cq'])
    # Save the DataFrame with the name 'PCR' followed by the number
    PCRs[f'PCR_{df_name}'] = PCR
# =============================================================================
# Normalize data ==============================================================
# =============================================================================
# Select the DataFrame 'PCR_s' from the dictionary PCRs and filter 
# rows where the value in the 'Sample' column is 'STD'
for PCR_name, PCR_df in PCRs.items():
    if PCR_name == 'PCR_1':
        STDs_from_PCR1_df = PCRs['PCR_1'][PCRs['PCR_1']['Sample'] == 'STD']
        average_STD_PCR1 = statistics.mean(STDs_from_PCR1_df['Cq'])
        STD_correction_PCR1 = 0
        PCR_df['Corrected_Cq'] = PCR_df['Cq'] - STD_correction_PCR1
    elif PCR_name != 'PCR_1':
        # Filter STD samples from the current DataFrame
        STDs_from_df = PCR_df[PCR_df['Sample'] == 'STD']
        # Calculate correction based on the average Cq value of PCR_1
        STD_correction = statistics.mean(STDs_from_df['Cq']) - average_STD_PCR1
        # Apply correction to the Cq values of the current DataFrame
        PCR_df['Corrected_Cq'] = PCR_df['Cq'] - STD_correction
# =============================================================================
# Making a standard curve =====================================================
# =============================================================================
# Select the DataFrame 'stdcurve' by filtering on 'Sample' starting with "10^"
stdcurve = PCRs['PCR_1'][PCRs['PCR_1']['Sample'].str.startswith("10^")]
# Remove the rows from 'PCR_1' that are already used in 'stdcurve'
PCR_1 = PCRs['PCR_1'].drop(stdcurve.index)
# Update the 'PCR_1' DataFrame in the PCRs dictionary
PCRs['PCR_1'] = PCR_1

# Drops all the reactions where the Cq is Nan
stdcurve = stdcurve.dropna()

stdcurve['power'] = (stdcurve["Sample"].str.split('^', expand=True)[1].astype(float))

# For each standard, calculate + add copies/µL and log_copies to the dataframe
for standard in stdcurve.index:
    power = stdcurve['power'][standard]
    copies = std_curve_copies * 10 ** power
    log_copies = math.log10(copies)
    stdcurve.loc[standard, 'copies/µL'] = copies
    stdcurve.loc[standard, 'log_copies'] = log_copies

# Linear regression + interpolation for standard curve
slope, yintercept, rv, pv, se = stats.linregress(stdcurve["log_copies"], 
                                                  stdcurve["Cq"])
interp = np.linspace(np.min(stdcurve['log_copies']), 
                            np.max(stdcurve['log_copies']), 
                            num=500)
# calculate efficiency
efficiency = (-1+10**(-1/slope))*100

# determine highest standard
max_power = max(stdcurve['power'])

# plot standard curve
fig, ax = plt.subplots(dpi=300)                 # empty plot
ax.set_xticks(np.arange(0,max_power + 1,1))     # x-grid intervals=1
ax.grid(alpha=0.3)                              # transparancy of grid
ax.set_title('Standardcurve', fontsize=16)
ax.scatter(stdcurve["log_copies"],              # x-axis
            stdcurve["Cq"],                     # y-axis
            c='blue')                           # color of the dots
ax.set_xlabel('log10 copies')                   # x-axis label
ax.set_ylabel('Cq')                             # y-axis label

# plot linear regression
ax.plot(interp,                     # x-axis
        yintercept + slope * interp,# y-axis
        linestyle='--',             # style of the line
        c='cornflowerblue'          # color of the line
        )

# add equation to plot
equation = "y = " + str(round(slope, 3)) + "X + " + str(round(yintercept,2))
ax.text(.7, 0.9, equation, 
        size=8, color='purple', 
        transform=ax.transAxes
        )
# add efficiency to plot
efficiency = "efficiency = " + str(round(efficiency)) + "%"
ax.text(.7, 0.85, efficiency, 
        size=8, color='purple', 
        transform=ax.transAxes)
# make layout fit better and save as a .png
plt.tight_layout()
plt.savefig(folder_path +"/" + analytical_run_code + "_standard_curve.png")
# =============================================================================
# Sample calculations =========================================================
# =============================================================================
# Creates an empty Dataframe with the columns Sample and Corrected_Cq
combined_data = pd.DataFrame(columns=['Sample', 'Corrected_Cq'])

# Iterates over each DataFrame in PCRs and adds every line that is not STD or
# starts with 10^ and adds them to the empty DataFrame above
for PCR_name, PCR_df in PCRs.items():
    for index, row in PCR_df.iterrows():
        if row['Sample'] != 'STD' or row['Sample'].startswith('10^'):
            combined_data.loc[len(combined_data)] = row[['Sample', 'Corrected_Cq']]

# Combine duplicate measurements
sample_calculations = combined_data.groupby('Sample')['Corrected_Cq'].apply(list).reset_index()

for index, row in sample_calculations.iterrows():
    # Iterate over each element in the list
    for i, value in enumerate(row['Corrected_Cq']):
        # Create a new column if it doesn't exist
        col_name = f'Corrected_Cq_{i + 1}'
        if col_name not in sample_calculations.columns:
            sample_calculations[col_name] = None  # or np.nan
        # Assign the value to the new column
        sample_calculations.at[index, col_name] = value

# Drop the original 'Corrected_Cq' column.
sample_calculations.drop(columns=['Corrected_Cq'], inplace=True)

# Convert columns except the one called "Sample" to numeric
columns_for_mean = sample_calculations.iloc[:, sample_calculations.columns!="Sample"].apply(pd.to_numeric, errors='coerce')

# Calculate the mean of numeric columns.
sample_calculations['Mean'] = columns_for_mean.mean(axis=1, skipna=True)

# Extracts the columns needed for the stdev calculation wich are not named "Sample" and "Mean".
columns_for_stdev = sample_calculations.columns[(sample_calculations.columns != "Sample") 
                                                & (sample_calculations.columns != "Mean")]

# Calculate the standard devition on the columns extracted above.
sample_calculations['Stdev'] = sample_calculations[columns_for_stdev].std(axis=1)

# Creates the pathway to the dilution file
dilution_file = folder_path +'/'+ analytical_run_code +'_dilution_rates.csv'

dilution_file_check = os.path.exists(dilution_file)

if dilution_file_check:
    # Reads the dilution rates file and uses the columns named 'Sample' and 'Dilution'
    dilutions = pd.read_csv((dilution_file), usecols=['Sample', 'Dilution'])
   
    # Merges the 2 dataframes and overwrites the sample_calculations column
    sample_calculations = pd.merge(dilutions, sample_calculations, on = 'Sample', how='left')
    
else:    
    print('You did not upload a dilution file. Therefor, all the sample are calculated as undiluted samples! If you did dilute your samples, please upload a dilution file in the folder where your raw data is located.')
    sample_calculations['Dilution'] = '1'

for sample in sample_calculations.index:
    # Calculate from std curve formula (10** because using log-copies)
    copies = 10**((sample_calculations["Mean"][sample] - yintercept) / slope)
    try:
    # Multiply by dilution factor
        copies = copies * sample_calculations["Dilution"][sample]
    except:
        pass
    # Add to dataframe, use scientific format, 2 decimal points
    sample_calculations.loc[sample, "Extract_copies/µL"] = (
        "{:.2e}".format(copies))

# The pathway for the excel file to save. Is used multiple times.
excel_file = folder_path + "/" + analytical_run_code + "_results.xlsx"

# Saves the dataframe as a .xlsx
sample_calculations.to_excel(excel_file, index = False)

# =============================================================================
# Creating scatterplot=========================================================
# =============================================================================
# Creates a list with the sample names and the mean
sample_names_list = sample_calculations['Sample'].tolist()
means_list = sample_calculations['Mean'].tolist()

# List of 10 different colors
colors = ['xkcd:tangerine','xkcd:electric lime','xkcd:cerulean','xkcd:burnt sienna',
          'xkcd:purple','xkcd:tomato','xkcd:mint','xkcd:peach','xkcd:grey',
          'xkcd:lavender']
# Creates the plot
fig, ax2 = plt.subplots(dpi=300)

# Loop through columns in sample_calculations
# for i, column in enumerate(sample_calculations.columns[sample_calculations.columns.str.startswith('Corrected')], start=1):
#     # Get the index from the column name
color = colors[(i - 1) % len(colors)]  # Cycle through colors list using modulus operator
    
#     # Extract data from the column and convert to list
#     cq_list = sample_calculations[column].tolist()
    
#     # Subtract corresponding elements and handle None values
#     result = []
#     for x, y in zip(means_list, cq_list):
#         if y is not None:
#             result.append(x - y)
#         else:
#             result.append(None)
    # Adds the data to the plot        
ax2.scatter(x=sample_names_list, y= sample_calculations['Stdev'], color=color, label=f"Cq {i}", marker='*')
    
# Specify x-axis and y-axis labels 
ax2.set_xticklabels(sample_names_list, rotation=90)  # Set x-axis labels with rotation
ax2.set_ylabel('Stdev')  # Set y-axis label
ax2.set_title('Stdev per sample')  # Set title for the plot
ax2.legend() # Adds the legend to the file

# Makes the plot nicer, saves it and shows it
plt.tight_layout()
plt.savefig(folder_path +"/" + analytical_run_code + "_difference_to_mean.png")
plt.show()
# =============================================================================
# Excel formatting  ===========================================================
# =============================================================================
# Load the existing Excel file
wb = load_workbook(excel_file)
ws = wb.active

# Define function to apply color scale rule to a column
def apply_color_scale_rule(ws, column_header, color_rule):
    # Search for the column dynamically
    column_index = None
    for col_idx, col in enumerate(ws.iter_cols()):
        if col[0].value == column_header:
            column_index = col_idx + 1
            break

    # Check if the column was found
    if column_index is None:
        raise ValueError(f"Column named '{column_header}' not found in the Excel file")
    # Convert column index to letter
    column_letter = get_column_letter(column_index)
    # Define the range of the column
    column_range = f"{column_letter}2:{column_letter}{ws.max_row}"
    # Apply color scale rule to the column
    ws.conditional_formatting.add(column_range, color_rule)

# Create color scale rule for 'Stdev' column
# Apply color scale rule to 'Stdev' column
color_scale_rule_stdev = ColorScaleRule(start_type="min", start_color="D0FDD5",
                                        end_type="max", end_color="FDD0D0")
apply_color_scale_rule(ws, 'Stdev', color_scale_rule_stdev)

# Create color scale rule for 'Mean' column
# Apply color scale rule to 'Mean' column
color_scale_rule_mean = ColorScaleRule(start_type="min", start_color="D0FDD5",
                                       end_type="max", end_color="FDD0D0")
apply_color_scale_rule(ws, 'Mean', color_scale_rule_mean)
# Save the workbook with the conditional formatting applied
wb.save(excel_file)
# Close the file to release system resources
wb.close()
print('Your file and standard curve has been saved at the given location')